# -*- coding: utf-8 -*-
"""fema_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oil-R4Fppd3zdp7TRoklRHPcp5VCF5Rc

Dataset Load
"""

import urllib.request, os, time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

url = "https://storage.googleapis.com/info_450/IndividualAssistanceHousingRegistrantsLargeDisasters%20(1).csv"
filename = "fema_disaster_data.csv"

start = time.time()
print(f" Downloading {filename}...")
urllib.request.urlretrieve(url, filename)

df = pd.read_csv(filename)
print("loaded", df.shape)

"""Part 1"""

data = df.copy()

data['grossIncome'] = data['grossIncome'].replace({
    1: "<$15k", 2: "$15k-30k", 3: "$30k-50k",
    4: "$50k-75k", 5: "$75k-100k", 6: "$100k+"
})
data['grossIncome'] = data['grossIncome'].fillna("Unknown")
data['residenceType'] = data['residenceType'].fillna("Unknown")
data['waterLevel_missing'] = data['waterLevel'].isna().astype(int)
data['destroyed'] = data['destroyed'].fillna(0)
data['specialNeeds'] = data['specialNeeds'].fillna("Unknown")

data.isna().sum()

ct = pd.crosstab(data['residenceType'], data['tsaEligible'], normalize='index') * 100
print("TSA Eligibility by Residence Type (%):")
ct

ct_state = pd.crosstab(data['damagedStateAbbreviation'], data['tsaEligible'], normalize='index') * 100
print("TSA Eligibility by State (%):")
ct_state

avg_repair = data.groupby('damagedStateAbbreviation')['repairAmount'].mean().sort_values(ascending=False)
avg_repair.head(10)

"""Bar Chart"""

tsa_rate = data.groupby("damagedStateAbbreviation")['tsaEligible'].mean()

plt.figure(figsize=(12,6))
tsa_rate.sort_values().plot(kind='bar')
plt.title("TSA Eligibility Rate by State")
plt.xlabel("State")
plt.ylabel("Eligibility Rate (%)")
plt.tight_layout()
plt.show()

"""Histogram"""

plt.figure(figsize=(10,5))
plt.hist(data['repairAmount'].dropna(), bins=40)
plt.title("Distribution of Repair Amount")
plt.xlabel("Repair Amount ($)")
plt.ylabel("Frequency")
plt.show()

"""Boxplot"""

plt.figure(figsize=(12,6))
data.boxplot(column='repairAmount', by='residenceType', rot=45)
plt.title("Repair Amount by Residence Type")
plt.suptitle("")  # removes default title
plt.xlabel("Residence Type")
plt.ylabel("Repair Amount ($)")
plt.show()

"""Analyst choice



"""

income_tsa_rate = data.groupby("grossIncome")["tsaEligible"].mean().sort_values()

plt.figure(figsize=(10,5))
income_tsa_rate.plot(kind='bar')
plt.title("TSA Eligibility Rate by Gross Income Level")
plt.xlabel("Gross Income Category")
plt.ylabel("TSA Eligibility Rate")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Part 2"""

eligible = data.loc[data['tsaEligible'] == 1, 'repairAmount']
not_eligible = data.loc[data['tsaEligible'] == 0, 'repairAmount']
eligible_valid = eligible[eligible.notna()]
not_eligible_valid = not_eligible[not_eligible.notna()]

from scipy import stats

def mean_ci(series, confidence=0.95):
    mean = series.mean()
    se = stats.sem(series)
    ci = stats.t.interval(confidence, len(series)-1, loc=mean, scale=se)
    return mean, ci
mean_e, ci_e = mean_ci(eligible_valid)
mean_ne, ci_ne = mean_ci(not_eligible_valid)

mean_e, ci_e, mean_ne, ci_ne

state1 = "FL"
state2 = "LA"
s1 = data.loc[data['damagedStateAbbreviation'] == state1, 'repairAmount']
s2 = data.loc[data['damagedStateAbbreviation'] == state2, 'repairAmount']

s1_valid = s1[s1.notna()]
s2_valid = s2[s2.notna()]

mean_s1, ci_s1 = mean_ci(s1_valid)
mean_s2, ci_s2 = mean_ci(s2_valid)

mean_s1, ci_s1, mean_s2, ci_s2

t_stat_1, p_val_1 = stats.ttest_ind(eligible_valid, not_eligible_valid, equal_var=False)
t_stat_1, p_val_1

t_stat_2, p_val_2 = stats.ttest_ind(s1_valid, s2_valid, equal_var=False)
t_stat_2, p_val_2

"""Part 3"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix

data_small, _ = train_test_split(
    data,
    train_size=200000,
    random_state=42,
    stratify=data["tsaEligible"]
)

print("Original dataset size:", len(data))
print("Sampled dataset size:", len(data_small))

predictors = ["grossIncome","repairAmount","destroyed","waterLevel","residenceType","damagedStateAbbreviation"]

X = data_small[predictors].copy()
y = data_small["tsaEligible"]

X['grossIncome'] = X['grossIncome'].fillna("Unknown").astype(str)
X['residenceType'] = X['residenceType'].fillna("Unknown")
X['damagedStateAbbreviation'] = X['damagedStateAbbreviation'].fillna("Unknown")

X['repairAmount'] = X['repairAmount'].fillna(0)
X['waterLevel'] = X['waterLevel'].fillna(0)

categorical_cols = ["grossIncome", "residenceType", "damagedStateAbbreviation"]
numeric_cols = ["repairAmount", "destroyed", "waterLevel"]

preprocess = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ("num", "passthrough", numeric_cols)
    ]
)

"""Split train"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

X_train_transformed = preprocess.fit_transform(X_train)
X_test_transformed = preprocess.transform(X_test)

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train_transformed, y_train)
dt_pred = dt_model.predict(X_test_transformed)

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_transformed, y_train)
rf_pred = rf_model.predict(X_test_transformed)

def evaluate_model(name, y_true, y_pred):
    print(f"--- {name} ---")
    print(f"Accuracy:  {accuracy_score(y_true, y_pred):.3f}")
    print(f"Precision: {precision_score(y_true, y_pred):.3f}")
    print(f"Recall:    {recall_score(y_true, y_pred):.3f}")
    print("Confusion Matrix:")
    print(confusion_matrix(y_true, y_pred))
    print()

evaluate_model("Decision Tree", y_test, dt_pred)
evaluate_model("Random Forest", y_test, rf_pred)

"""Part 5"""

import streamlit as st
import pandas as pd
import plotly.express as px

st.set_page_config(page_title="FEMA Disaster Relief Dashboard", layout="wide")

st.title("FEMA Disaster Relief Dashboard")


df = pd.read_csv("https://storage.googleapis.com/info_450/IndividualAssistanceHousingRegistrantsLargeDisasters%20(1).csv")

st.subheader("Data Preview")
st.write(df.head())


st.subheader("Histogram of Repair Amount")

fig_hist = px.histogram(
    df,
    x="repairAmount",
    nbins=40,
    title="Distribution of Repair Amounts",
    labels={"repairAmount": "Repair Amount (USD)"}
)

st.plotly_chart(fig_hist, use_container_width=True)

st.markdown(
    """
    **Insight:**
    The histogram shows how repair costs are distributed across households.
    We can see whether most people report smaller repair amounts or if there are many large, high-damage cases.
    """
)


st.subheader("Boxplot: Repair Amount by TSA Eligibility")

df["tsaEligible_label"] = df["tsaEligible"].map({0: "Not Eligible", 1: "Eligible"})

fig_box = px.box(
    df,
    x="tsaEligible_label",
    y="repairAmount",
    title="Repair Amount by TSA Eligibility",
    labels={
        "tsaEligible_label": "TSA Eligibility",
        "repairAmount": "Repair Amount (USD)"
    }
)

st.plotly_chart(fig_box, use_container_width=True)

st.markdown(
)
